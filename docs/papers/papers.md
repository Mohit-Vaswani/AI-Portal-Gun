---
hide:
  - navigation
---

# Research Papers

Below, you'll find the latest, highly-cited papers, organized by their release date. We keep this list updated on a weekly basis for the most current research.

<!-- <img src="/assets/images/r&dMeme.png" alt="R&D meme" /> -->

- [MemGPT: Towards LLMs as Operating Systems](https://arxiv.org/abs/2310.08560) (Oct 2023)
- [Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models](https://arxiv.org/abs//2310.06117) (Oct 2023)
- [Introducing The Foundation Model Transparency Index](https://hai.stanford.edu/news/introducing-foundation-model-transparency-index)
- [Improving Image Generation with Better Captions](https://cdn.openai.com/papers/dall-e-3.pdf)
- [Habitat 3.0: A Co-Habitat for Humans, Avatars and RobotsHabitat 3.0: A Co-Habitat for Humans, Avatars and Robots](https://aihabitat.org/habitat3/)
- [Self-RAG: Learning to Retrieve, Generate and Critique through Self-Reflections](https://selfrag.github.io/) (Oct 2023)
- [Improved Baselines with Visual Instruction Tuning](https://browse.arxiv.org/pdf/2310.03744.pdf) (Oct 2023)
- [Open X-Embodiment: Robotic Learning Datasets and RT-X Models](https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/scaling-up-learning-across-many-different-robot-types/Open_X_Embodiment__Robotic_Learning_Datasets_and_RT_X_Models.pdf) (Oct 2023)
- [Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation](https://arxiv.org/pdf/2310.02304.pdf) (Oct 2023)
- [RealFill: Reference-Driven Generation for Authentic Image Completion](https://arxiv.org/abs/2309.16668) (Sept 2023)

## LLMs

## Generative AI

### Image Generation 


### Audio Generation 
### Video Generation 


### Code Generation 
### Multimodel

### Prompt Engineering
## Robotics


## Healthcare & Biology

## Approaches

## Reinforcement Learning

### Deep RL Key Papers

- [Playing Atari with Deep Reinforcement Learning](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf) (2013): Presents the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning.
- [Deep Recurrent Q-Learning for Partially Observable MDPs](https://arxiv.org/abs/1507.06527) (2015): Proposes a deep recurrent Q-learning algorithm for partially observable Markov decision processes.
- [Dueling Network Architectures for Deep Reinforcement Learning](https://arxiv.org/abs/1511.06581) (2015): Introduces a dueling network architecture for deep reinforcement learning that separates the estimation of state values and state-dependent action advantages.
- [Deep Reinforcement Learning with Double Q-learning](https://arxiv.org/abs/1509.06461) (2015): Proposes a double Q-learning algorithm for deep reinforcement learning that reduces overestimation of action values.
- [Prioritized Experience Replay](https://arxiv.org/abs/1511.05952) (2015):  Introduces a prioritized experience replay mechanism for deep reinforcement learning that improves sample efficiency and learning speed.
- [Rainbow: Combining Improvements in Deep Reinforcement Learning](https://arxiv.org/abs/1710.02298) (2017): Combines several improvements to deep reinforcement learning, including dueling networks, double Q-learning, and prioritized experience replay, to achieve state-of-the-art performance on Atari games.
- [Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/abs/1602.01783) (2016): Proposes asynchronous methods for deep reinforcement learning that improve sample efficiency and learning speed.
- [Trust Region Policy Optimization](https://arxiv.org/abs/1502.05477) (2015): Introduces a trust region optimization method for policy optimization in reinforcement learning that improves stability and sample efficiency.
- [High-Dimensional Continuous Control Using Generalized Advantage Estimation](https://arxiv.org/abs/1506.02438) (2015): Proposes a generalized advantage estimation method for continuous control tasks in reinforcement learning that improves sample efficiency and learning speed.
- [Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347) (2017): Introduces a family of proximal policy optimization algorithms for reinforcement learning that improve sample efficiency and stability.
- [Emergence of Locomotion Behaviours in Rich Environments](https://arxiv.org/abs/1707.02286) (2017): Demonstrates the emergence of diverse locomotion behaviors in simulated environments using deep reinforcement learning.
- [Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation](https://arxiv.org/abs/1708.05144) (2017): Proposes a scalable trust-region method for deep reinforcement learning that uses Kronecker-factored approximation to improve sample efficiency and learning speed.
- [Sample Efficient Actor-Critic with Experience Replay](https://arxiv.org/abs/1611.01224) (2016): Introduces a sample-efficient actor-critic algorithm with experience replay for reinforcement learning that improves sample efficiency and learning speed.
- [Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor](https://arxiv.org/abs/1801.01290) (2018): Proposes a soft actor-critic algorithm for deep reinforcement learning that maximizes entropy and improves exploration.
- [Deterministic Policy Gradient Algorithms](http://proceedings.mlr.press/v32/silver14.pdf) (2014): Introduces a deterministic policy gradient algorithm for reinforcement learning that improves sample efficiency and stability.
- [Continuous Control With Deep Reinforcement Learning](https://arxiv.org/abs/1509.02971) (2015): Demonstrates the effectiveness of deep reinforcement learning for continuous control tasks.
- [Addressing Function Approximation Error in Actor-Critic Methods](https://arxiv.org/abs/1802.09477) (2018): Addresses the problem of function approximation error in actor-critic methods for reinforcement learning.
- [A Distributional Perspective on Reinforcement Learning](https://arxiv.org/abs/1707.06887) (2017): Presents a distributional perspective on reinforcement learning that improves sample efficiency and learning speed.
- [Distributional Reinforcement Learning with Quantile Regression](https://arxiv.org/abs/1710.10044) (2017): Proposes a distributional reinforcement learning algorithm that uses quantile regression to estimate value distributions.
- [Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/abs/1806.06923) (2018): Introduces implicit quantile networks for distributional reinforcement learning that improve sample efficiency and learning speed.
- [Dopamine: A Research Framework for Deep Reinforcement Learning](https://openreview.net/forum?id=ByG_3s09KX) (2018) [(code)](https://github.com/google/dopamine): Provides a research framework for deep reinforcement learning that includes a suite of environments and baselines.
- [Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic](https://arxiv.org/abs/1611.02247) (2016): Proposes a sample-efficient policy gradient algorithm with an off-policy critic for reinforcement learning that improves sample efficiency and learning speed.
- [Action-depedent Control Variates for Policy Optimization via Steinâ€™s Identity,](https://arxiv.org/abs/1710.11198) (2017): Proposes a control variate method for policy optimization in reinforcement learning that improves sample efficiency and stability.
- [The Mirage of Action-Dependent Baselines in Reinforcement Learning](https://arxiv.org/abs/1802.10031) (2018): Critiques the use of action-dependent baselines in reinforcement learning and proposes alternative methods.
- [Bridging the Gap Between Value and Policy Based Reinforcement Learning](https://arxiv.org/abs/1702.08892) (2017): Proposes a method for bridging the gap between value-based and policy-based reinforcement learning.
- [Trust-PCL: An Off-Policy Trust Region Method for Continuous Control](https://arxiv.org/abs/1707.01891) (2017): Introduces an off-policy trust region method for continuous control in reinforcement learning that improves sample efficiency and stability.
- [Combining Policy Gradient and Q-learning](https://arxiv.org/abs/1611.01626) (2016): Combines policy gradient and Q-learning methods for reinforcement learning to improve sample efficiency and stability.
- [The Reactor: A Fast and Sample-Efficient Actor-Critic Agent for Reinforcement Learning](https://arxiv.org/abs/1704.04651) (2017): Introduces a fast and sample-efficient actor-critic algorithm for reinforcement learning that improves sample efficiency and learning speed.
- [Interpolated Policy Gradient: Merging On-Policy and Off-Policy Gradient Estimation for Deep Reinforcement Learning](http://papers.nips.cc/paper/6974-interpolated-policy-gradient-merging-on-policy-and-off-policy-gradient-estimation-for-deep-reinforcement-learning) (2017): Proposes an interpolated policy gradient algorithm for deep reinforcement learning that combines on-policy and off-policy gradient estimation.
- [Equivalence Between Policy Gradients and Soft Q-Learning](https://arxiv.org/abs/1704.06440) (2017): Shows the equivalence between policy gradients and soft Q-learning in reinforcement learning.
- [Evolution Strategies as a Scalable Alternative to Reinforcement Learning](https://arxiv.org/abs/1703.03864) (2017)
- [VIME: Variational Information Maximizing Exploration](https://arxiv.org/abs/1605.09674) (2016)
- [Unifying Count-Based Exploration and Intrinsic Motivation](https://arxiv.org/abs/1606.01868) (2016)
- [Count-Based Exploration with Neural Density Models](https://arxiv.org/abs/1703.01310) (2017)
- [#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning](https://arxiv.org/abs/1611.04717) (2016)
- [EX2: Exploration with Exemplar Models for Deep Reinforcement Learning](https://arxiv.org/abs/1703.01260) (2017)
- [Curiosity-driven Exploration by Self-supervised Prediction](https://arxiv.org/abs/1705.05363) (2017)
- [Large-Scale Study of Curiosity-Driven Learning](https://arxiv.org/abs/1808.04355) (2018)
- [Exploration by Random Network Distillation](https://arxiv.org/abs/1810.12894) (2018)
- [Variational Intrinsic Control](https://arxiv.org/abs/1611.07507) (2016)
- [Diversity is All You Need: Learning Skills without a Reward Function](https://arxiv.org/abs/1802.06070) (2018)
- [Variational Option Discovery Algorithms](https://arxiv.org/abs/1807.10299) (2018)
- [Progressive Neural Networks](https://arxiv.org/abs/1606.04671) (2016)
- [Universal Value Function Approximators](http://proceedings.mlr.press/v37/schaul15.pdf) (2015)
- [The Intentional Unintentional Agent: Learning to Solve Many Continuous Control Tasks Simultaneously](https://arxiv.org/abs/1707.03300) (2017)
- [PathNet: Evolution Channels Gradient Descent in Super Neural Networks](https://arxiv.org/abs/1701.08734) (2017)
- [Mutual Alignment Transfer Learning](https://arxiv.org/abs/1707.07907) (2017)
- [Learning an Embedding Space for Transferable Robot Skills](https://openreview.net/forum?id=rk07ZXZRb&noteId=rk07ZXZRb) (2018)
- [Hindsight Experience Replay](https://arxiv.org/abs/1707.01495) (2017)
- [Strategic Attentive Writer for Learning Macro-Actions](https://arxiv.org/abs/1606.04695) (2016)
- [FeUdal Networks for Hierarchical Reinforcement Learning](https://arxiv.org/abs/1703.01161) (2017)
- [Data-Efficient Hierarchical Reinforcement Learning](https://arxiv.org/abs/1805.08296)
(2018)
- [Model-Free Episodic Control](https://arxiv.org/abs/1606.04460) (2016)
- [Neural Episodic Control](https://arxiv.org/abs/1703.01988) (2017)
- [Neural Map: Structured Memory for Deep Reinforcement Learning](https://arxiv.org/abs/1702.08360) (2017):
- [Unsupervised Predictive Memory in a Goal-Directed Agent](https://arxiv.org/abs/1803.10760) (2018):
- [	Relational Recurrent Neural Networks](https://arxiv.org/abs/1806.01822) (2018)
- [Imagination-Augmented Agents for Deep Reinforcement Learning](https://arxiv.org/abs/1707.06203) (2017):
- [Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning](https://arxiv.org/abs/1708.02596) (2017):
- [Model-Based Value Expansion for Efficient Model-Free Reinforcement Learning](https://arxiv.org/abs/1803.00101) (2018):
- [Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion](https://arxiv.org/abs/1807.01675) (2018):
- [Model-Ensemble Trust-Region Policy Optimization](https://openreview.net/forum?id=SJJinbWRZ&noteId=SJJinbWRZ) (2018):
- [Model-Based Reinforcement Learning via Meta-Policy Optimization](https://arxiv.org/abs/1809.05214) (2018)
- [Recurrent World Models Facilitate Policy Evolution](https://arxiv.org/abs/1809.01999) (2018)
- [Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm](https://arxiv.org/abs/1712.01815) (2017):
- [Thinking Fast and Slow with Deep Learning and Tree Search](https://arxiv.org/abs/1705.08439) (2017):
- [RL^2: Fast Reinforcement Learning via Slow Reinforcement Learning](https://arxiv.org/abs/1611.02779) (2016):
- [Learning to Reinforcement Learn](https://arxiv.org/abs/1611.05763) (2016):
- [Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks](https://arxiv.org/abs/1703.03400) (2017):
- [A Simple Neural Attentive Meta-Learner](https://openreview.net/forum?id=B1DmUzWAW&noteId=B1DmUzWAW) (2018):
- [Accelerated Methods for Deep Reinforcement Learning](https://arxiv.org/abs/1803.02811) (2018):
- [IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures](https://arxiv.org/abs/1802.01561) (2018):
- [Distributed Prioritized Experience Replay](https://openreview.net/forum?id=H1Dy---0Z) (2018):
- [Recurrent Experience Replay in Distributed Reinforcement Learning](https://openreview.net/forum?id=r1lyTjAqYX) (2018):
- [RLlib: Abstractions for Distributed Reinforcement Learning](https://arxiv.org/abs/1712.09381) (2017): [(docs)](https://ray.readthedocs.io/en/latest/rllib.html)
- [Benchmarking Reinforcement Learning Algorithms on Real-World Robots](https://arxiv.org/abs/1809.07731) (2018):
- [Learning Dexterous In-Hand Manipulation](https://arxiv.org/abs/1808.00177) (2018):
- [QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation](https://arxiv.org/abs/1806.10293) (2018):



## Quantum Machine Learning

- [Quantum Machine Learning]() (2014) - Early paper outlining basic goals and approaches for quantum ML.
- [Quantum algorithms for supervised and unsupervised machine learning]() (2013) - Proposes quantum algorithms for supervised classification and unsupervised clustering.
- [Quantum Neural Networks]() (2018) - Describes a quantum version of neural networks with quantum circuits.
- [Quantum variational autoencoder]() (2017) - Implements a variational autoencoder using parametrized quantum circuits.
- [Quantum Boltzmann Machine]() (2018) - Proposes a generative quantum model based on Boltzmann machines.
- [Quantum generative adversarial networks]() (2018) - Formulates a quantum version of GANs using quantum circuits.
- [Quantum graph neural networks]() (2019) - Applies quantum circuits for graph representation learning.
- [Quantum algorithms for topological and geometric analysis of data]() (2016) - Presents quantum algorithms for data topology/geometry.
- [Quantum reinforcement learning]() (2008) - An early approach to quantum reinforcement learning using superposition of states.

## Collections 

- [Key Papers in Deep RL](https://spinningup.openai.com/en/latest/spinningup/keypapers.html#) by Open AI Spinning Up